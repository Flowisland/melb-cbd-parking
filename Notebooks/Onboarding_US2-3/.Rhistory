library(tidyverse)
library(lubridate)
# Store T20 URL as an object named t20_url
t20i_page <- "https://en.wikipedia.org/wiki/ICC_Men%27s_T20I_Team_Rankings"
# Scrape T20 data
t20i_page <- read_html(t20i_page)
library(rvest)
library(tidyverse)
library(lubridate)
# Store T20 URL as an object named t20_url
t20i_page <- GET("https://en.wikipedia.org/wiki/ICC_Men%27s_T20I_Team_Rankings", user_agent("Mozilla/5.0"))
library(rvest)
library(tidyverse)
library(lubridate)
library(httr)
# Store T20 URL as an object named t20_url
t20i_page <- GET("https://en.wikipedia.org/wiki/ICC_Men%27s_T20I_Team_Rankings", user_agent("Mozilla/5.0"))
# Scrape T20 data
t20i_page <- read_html(t20i_page)
t20i_table <- html_nodes(t20i_page, "table.wikitable") %>% html_table() %>% .[[6]]
# remove the square bracket and remove the last row
t20i_table <- t20i_table %>% mutate(Start=gsub("\\[\\d+\\]", "", Start), End=gsub("\\[\\d+\\]", "", End)) %>% filter(row_number()<=n()-1)
t20i_table[nrow(t20i_table),"End"] <- "10-10-2024"
t20i_table <- t20i_table %>% mutate(Start=dmy(Start), End=dmy(End), Duration=as.numeric(gsub("day|days", "", Duration)))
summarised_table<- t20i_table %>% group_by(Country) %>% summarise(Earliest_start=min(Start), Latest_end=max(End), Average_duration=round(mean(Duration),2)) %>%
arrange(desc(Average_duration))
summarised_table
f1_page <- "https://www.formula1.com/en/results/2023/drivers"
f1_page <- read_html(f1_page)
f1_table <- html_nodes(f1_page, "table.f1-table.f1-table-with-data.w-full") %>% html_table() %>% .[[1]]
f1_table$Code <- substr(f1_table$Driver, nchar(f1_table$Driver)-2, nchar(f1_table$Driver))
f1_table$Driver <- substr(f1_table$Driver, 1, nchar(f1_table$Driver)-3)
library(ggplot2)
library(forcats)
summarised_table <- f1_table %>% group_by(Car) %>% summarise(Pts_Team=sum(Pts)) %>% arrange(desc(Pts_Team))
ggplot(summarised_table, aes(x=fct_reorder(Car, Pts_Team), y=Pts_Team)) + geom_bar(stat = "identity") +
coord_flip() + geom_text(aes(label=Pts_Team), hjust=-0.005) + ggtitle("2023 F1 Constructor Standings") + xlab("Constructors") + ylab("Points")
library(tidyverse)
birth <- read_csv("Births.csv")
death <- read_csv("Deaths.csv")
tfr <- read_csv("TFR.csv")
birth_gather <- gather(birth, "States", "Count", -Year)
death_gather <- gather(death, "States", "Count", -Year)
p1 <- ggplot(birth_gather, aes(x=Year, y=Count, group=States, col=States)) + geom_line() +
ggtitle("Number of Births in Each State or Territory (1977-2016)") + theme(plot.title = element_text(hjust = 0.5)) + ylab("No. of Births") + xlab("Years")
p2 <- ggplot(death_gather, aes(x=Year, y=Count, group=States, col=States)) + geom_line() +
ggtitle("Number of Deaths in Each State or Territory (1977-2016)") + theme(plot.title = element_text(hjust = 0.5)) + ylab("No. of Deaths") + xlab("Years")
library(gridExtra)
grid.arrange(p1, p2, ncol=1)
library(naniar)
miss <- miss_summary(birth)
miss$miss_var_summary
miss <- miss_summary(death)
miss$miss_var_summary
birth$NSW[is.na(birth$NSW)] <- as.integer(mean(birth$NSW, na.rm = TRUE))
birth_gather <- gather(birth, "States", "Count", -Year)
death_gather <- gather(death, "States", "Count", -Year)
p1 <- ggplot(birth_gather, aes(x=Year, y=Count, group=States, col=States)) + geom_line() +
ggtitle("Number of Births in Each State or Territory (1977-2016)") + theme(plot.title = element_text(hjust = 0.5)) + ylab("No. of Births") + xlab("Years")
p2 <- ggplot(death_gather, aes(x=Year, y=Count, group=States, col=States)) + geom_line() +
ggtitle("Number of Deaths in Each State or Territory (1977-2016)") + theme(plot.title = element_text(hjust = 0.5)) + ylab("No. of Deaths") + xlab("Years")
library(gridExtra)
grid.arrange(p1, p2, ncol=1)
natural_growth <- birth
for (i in 2:length(colnames(birth))){
natural_growth[,colnames(birth)[i]] <- birth[,colnames(birth)[i]] - death[,colnames(birth)[i]]
}
natural_growth <- natural_growth %>% mutate(total_growth=rowSums(natural_growth[2:9]))
ggplot(natural_growth, aes(x=Year, y=total_growth)) + geom_line() +
ggtitle("The Natural Growth in Australia's Population (1977-2016)") + theme(plot.title = element_text(hjust = 0.5)) + ylab("No. natural growth") + xlab("Years")
tfr %>% filter(tfr$QLD==min(tfr$QLD))
# CPI
nsw <- tfr %>% filter(Year!=1971) %>% select(Year, NSW)
cpi <- read_csv("CPI.csv") %>% select(`TIME_PERIOD: Time Period`, OBS_VALUE)
cpi <- cpi %>% mutate(Year = sub("-Q[1-4]", "", `TIME_PERIOD: Time Period`)) %>% select(-`TIME_PERIOD: Time Period`) %>% group_by(Year) %>%
summarise(Avg = mean(OBS_VALUE), .groups = "drop")
cpi$Year <-as.numeric(cpi$Year)
combined_data <- left_join(nsw, cpi, by = "Year")
max_TFR <- max(combined_data$NSW, na.rm = TRUE)
max_CPI <- max(combined_data$Avg, na.rm = TRUE)
scale_factor <- max_TFR / max_CPI
ggplot(combined_data, aes(x = Year)) +
geom_line(aes(y = NSW), color = "blue") +
geom_line(aes(y = Avg * scale_factor), color = "red") +
scale_y_continuous(
name = "Total Fertility Rate (TFR)",
sec.axis = sec_axis(~ . / scale_factor, name = "Average CPI")
) +
labs(title = "TFR and CPI in NSW (1970-2015)", x = "Year") +
theme_minimal() +
theme(
plot.title = element_text(hjust = 0.5),
axis.title.y.left = element_text(color = "blue"),
axis.title.y.right = element_text(color = "red")
)
# CPI
print(paste0("Correlatio Coefficient: ", round(cor(combined_data$NSW, combined_data$Avg),2)))
nsw <- tfr %>% select(Year, NSW)
enroll <- read_csv("enrollment.csv")
header <- enroll[1,]
colnames(enroll) <- header
enroll <- enroll[-1,]
enroll <- enroll %>% filter(Year>=1971, Year<=2015) %>% select(Year, total)
enroll$Year <-as.numeric(enroll$Year)
enroll$total <-as.numeric(enroll$total)
combined_data <- left_join(nsw, enroll, by = "Year")
max_TFR <- max(combined_data$NSW, na.rm = TRUE)
max_enroll <- max(combined_data$total, na.rm = TRUE)
scale_factor <- max_TFR / max_enroll
ggplot(combined_data, aes(x = Year)) +
geom_line(aes(y = NSW), color = "blue") +
geom_line(aes(y = total * scale_factor), color = "red") +
scale_y_continuous(
name = "Total Fertility Rate (TFR)",
sec.axis = sec_axis(~ . / scale_factor, name = "Total Number of Enrollment")
) +
labs(title = "TFR and Total Number of Enrollment in Government Schools in NSW (1970-2015)", x = "Year") +
theme_minimal() +
theme(
plot.title = element_text(hjust = 0.5),
axis.title.y.left = element_text(color = "blue"),
axis.title.y.right = element_text(color = "red")
)
print(paste0("Correlatio Coefficient: ", round(cor(combined_data$NSW, combined_data$total),2)))
nom <- read_csv("NOM.csv")
nim <- read_csv("NIM.csv")
nom_gather <- gather(nom, "States", "Count", -Year)
nom_gather %>% filter(States %in% c("VIC", "TAS", "WA")) %>%
ggplot(aes(x=Year, y=Count, group=States, col=States)) + geom_line() +
ggtitle("Net Overseas Migration in TAS, VIC and WA (1977-2016)") + theme(plot.title = element_text(hjust = 0.5)) + ylab("No. of Migration") + xlab("Years")
nom <- nom %>% mutate(total_count=rowSums(nom[2:9]))
nom %>% ggplot(aes(x=Year, y=total_count)) + geom_line() +
ggtitle("Net Overseas Migration in Australia (1977-2016)") + theme(plot.title = element_text(hjust = 0.5)) + ylab("No. of Migration") + xlab("Years")
# Participation Rate
nom <- nom %>% filter(Year != 1977)
par <- read_csv("participation.csv") %>% select(`TIME_PERIOD: Time Period`, OBS_VALUE)
par <- par %>% mutate(Year = sub("-[0-9][0-9]", "", `TIME_PERIOD: Time Period`)) %>% select(-`TIME_PERIOD: Time Period`) %>% group_by(Year) %>%
summarise(Avg = mean(OBS_VALUE), .groups = "drop")
par$Year <-as.numeric(par$Year)
combined_data <- left_join(nom, par, by = "Year") %>% select(Year, total_count, Avg)
max_mig <- max(combined_data$total_count, na.rm = TRUE)
max_emp <- max(combined_data$Avg, na.rm = TRUE)
scale_factor <- max_mig / max_emp
ggplot(combined_data, aes(x = Year)) +
geom_line(aes(y = total_count), color = "blue") +
geom_line(aes(y = Avg * scale_factor), color = "red") +
scale_y_continuous(
name = "No. of Migration",
sec.axis = sec_axis(~ . / scale_factor, name = "Participation Rate")
) +
labs(title = "NOM and Participation Rate in Australia (1977-2016)", x = "Year") +
theme_minimal() +
theme(
plot.title = element_text(hjust = 0.5),
axis.title.y.left = element_text(color = "blue"),
axis.title.y.right = element_text(color = "red")
)
print(paste0("Correlatio Coefficient: ", round(cor(combined_data$total_count, combined_data$Avg),2)))
# Wage Price Index
nom <- nom %>% filter(Year>=1997, Year<=2016)
wage <- read_csv("wage.csv") %>% select(`TIME_PERIOD: Time Period`, OBS_VALUE)
wage <- wage %>% mutate(Year = sub("-Q[0-9]", "", `TIME_PERIOD: Time Period`)) %>% select(-`TIME_PERIOD: Time Period`) %>% group_by(Year) %>%
summarise(Avg = mean(OBS_VALUE), .groups = "drop")
wage$Year <-as.numeric(wage$Year)
combined_data <- left_join(nom, wage, by = "Year") %>% select(Year, total_count, Avg)
max_mig <- max(combined_data$total_count, na.rm = TRUE)
max_wag <- max(combined_data$Avg, na.rm = TRUE)
scale_factor <- max_mig / max_wag
ggplot(combined_data, aes(x = Year)) +
geom_line(aes(y = total_count), color = "blue") +
geom_line(aes(y = Avg * scale_factor), color = "red") +
scale_y_continuous(
name = "No. of Migration",
sec.axis = sec_axis(~ . / scale_factor, name = "Wage Price Index")
) +
labs(title = "NOM and Wage Price Index in Australia (1997-2016)", x = "Year") +
theme_minimal() +
theme(
plot.title = element_text(hjust = 0.5),
axis.title.y.left = element_text(color = "blue"),
axis.title.y.right = element_text(color = "red")
)
print(paste0("Correlatio Coefficient: ", round(cor(combined_data$total_count, combined_data$Avg),2)))
nom <- read_csv("NOM.csv")
nim <- read_csv("NIM.csv")
total_mig <- nim
for (i in 2:length(colnames(nim))){
total_mig[,colnames(nim)[i]] <- nom[,colnames(nim)[i]] + nim[,colnames(nim)[i]]
}
total_mig_gather <- gather(total_mig, "States", "Count", -Year)
highest <- total_mig_gather %>% group_by(Year) %>% filter(Count==max(Count)) %>% select(Year, States) %>% arrange(Year)
colnames(highest)[2] <- "highest_State"
lowest <- total_mig_gather %>% group_by(Year) %>% filter(Count==min(Count)) %>% select(Year, States) %>% arrange(Year)
colnames(lowest)[2] <- "lowest_State"
final_table <- merge(highest, lowest, by = "Year")
final_table
proportion <- total_mig_gather %>%
group_by(Year) %>%
mutate(Total = sum(Count)) %>%
mutate(Proportion = Count / Total) %>%
select(Year, States, Count, Proportion)
ggplot(proportion, aes(x = Year, y = Proportion, color = States)) + geom_line() +
facet_wrap(~ States, scales = "free_y") + labs(title = "Proportion of Total Migration by State for Each Year", x = "Year", y = "Proportion") +
theme(plot.title = element_text(hjust = 0.5))
# import required libraries
library(tidyverse)
library(rvest)
library(dplyr)
library(lubridate)
library(ggiraph)
library(ggplot2)
library(stringr)
library(tm)
library(caret)
library(randomForest)
library(sentimentr)
library(tidytext)
library(gbm)
# Load Datasets
useful_train <- read_csv("dialogue_usefulness_train.csv")
useful_valid <- read_csv("dialogue_usefulness_validation.csv")
useful_test <- read_csv("dialogue_usefulness_test.csv")
utterance_train <- read_csv("dialogue_utterance_train.csv")
utterance_valid <- read_csv("dialogue_utterance_validation.csv")
utterance_test <- read_csv("dialogue_utterance_test.csv")
utterance_train <- read_csv("dialogue_utterance_train.csv")
useful_train <- read_csv("dialogue_usefulness_train.csv")
num_utterance_train <- utterance_train %>% group_by(Dialogue_ID) %>% summarise(num_utterance = n())
num_utterance_train <- merge(num_utterance_train, useful_train, by="Dialogue_ID")
# Remove the dialogue with usefulness score is 3
num_utterance_train <- num_utterance_train %>% filter(Usefulness_score != 3) %>% mutate(score_group = ifelse(Usefulness_score %in% c(1,2), "1~2", "4~5"))
ggplot(num_utterance_train, aes(x=score_group, y= num_utterance, fill=score_group)) + geom_boxplot() + labs(x="Usefulness Score", y="No. of Utterances") +
ggtitle("Number of Utterance V.S. Usefulness Score")
t.test(data = num_utterance_train, num_utterance ~ score_group)
utterance_train <- read_csv("dialogue_utterance_train.csv")
useful_train <- read_csv("dialogue_usefulness_train.csv")
avg_len_utterance_train <- utterance_train %>% mutate(len_utterance = nchar(Utterance_text)) %>% group_by(Dialogue_ID) %>% summarise(avg_len = mean(len_utterance))
avg_len_utterance_train <- merge(avg_len_utterance_train, useful_train, by="Dialogue_ID")
# Remove the dialogue with usefulness score is 3
avg_len_utterance_train <- avg_len_utterance_train %>% filter(Usefulness_score != 3) %>% mutate(score_group = ifelse(Usefulness_score %in% c(1,2), "1~2", "4~5"))
ggplot(avg_len_utterance_train, aes(x=score_group, y= avg_len, fill=score_group)) + geom_boxplot() + labs(x="Usefulness Score", y="Avg. Length of Utterance") +
ggtitle("Average Length of Utterance V.S. Usefulness Score")
t.test(data = avg_len_utterance_train, avg_len ~ score_group)
useful_train <- read_csv("dialogue_usefulness_train.csv")
utterance_train <- read_csv("dialogue_utterance_train.csv") %>% group_by(Dialogue_ID) %>% summarise(combine_text = paste(Utterance_text, collapse = " ")) %>%
merge(useful_train, by = "Dialogue_ID") %>% filter(Usefulness_score>=4)
# Handle missing values
utterance_train <- na.omit(utterance_train)
# Text preprocessing
utterance_train$combine_text <- tolower(utterance_train$combine_text)
utterance_train$combine_text <- removePunctuation(utterance_train$combine_text)
utterance_train$combine_text <- removeNumbers(utterance_train$combine_text)
utterance_train$combine_text <- removeWords(utterance_train$combine_text, stopwords("en"))
utterance_train$combine_text <- stripWhitespace(utterance_train$combine_text)
# Create a document-term matrix
dtm <- DocumentTermMatrix(Corpus(VectorSource(utterance_train$combine_text)))
# Convert to a matrix and then to a data frame
dtm_matrix <- as.matrix(dtm)
dtm_df <- as.data.frame(dtm_matrix)
# Calculate term frequencies
term_frequencies <- colSums(dtm_df)
# Convert to a data frame
term_frequencies_df <- data.frame(term = names(term_frequencies), frequency = term_frequencies)
# Order by frequency
ordered_term_frequencies_df <- term_frequencies_df %>%
arrange(desc(frequency))
# View the ordered term frequencies
ordered_term_frequencies_df %>% top_n(10)
useful_train <- read_csv("dialogue_usefulness_train.csv")
utterance_train <- read_csv("dialogue_utterance_train.csv") %>% group_by(Dialogue_ID) %>% summarise(combine_text = paste(Utterance_text, collapse = " ")) %>%
merge(useful_train, by = "Dialogue_ID") %>% filter(Usefulness_score<=2)
# Handle missing values
utterance_train <- na.omit(utterance_train)
# Text preprocessing
utterance_train$combine_text <- tolower(utterance_train$combine_text)
utterance_train$combine_text <- removePunctuation(utterance_train$combine_text)
utterance_train$combine_text <- removeNumbers(utterance_train$combine_text)
utterance_train$combine_text <- removeWords(utterance_train$combine_text, stopwords("en"))
utterance_train$combine_text <- stripWhitespace(utterance_train$combine_text)
# Create a document-term matrix
dtm <- DocumentTermMatrix(Corpus(VectorSource(utterance_train$combine_text)))
# Convert to a matrix and then to a data frame
dtm_matrix <- as.matrix(dtm)
dtm_df <- as.data.frame(dtm_matrix)
# Calculate term frequencies
term_frequencies <- colSums(dtm_df)
# Convert to a data frame
term_frequencies_df <- data.frame(term = names(term_frequencies), frequency = term_frequencies)
# Order by frequency
ordered_term_frequencies_df <- term_frequencies_df %>%
arrange(desc(frequency))
# View the ordered term frequencies
ordered_term_frequencies_df %>% top_n(10)
useful_train <- read_csv("dialogue_usefulness_train.csv")
utterance_train <- read_csv("dialogue_utterance_train.csv")
train_data <- left_join(utterance_train, useful_train, by = "Dialogue_ID")
# Feature 1 - The Frequency of key words
keywords <- c("insights", "health", "predictive", "can")
keyword_freq_train <- train_data %>%
unnest_tokens(word, Utterance_text) %>%
filter(word %in% keywords) %>%
group_by(Dialogue_ID) %>%
summarise(keyword_frequency = n())
# Feature 2 - Sentiment Score
sentiment_scores_train <- train_data %>%
group_by(Dialogue_ID) %>%
summarise(sentiment_score = mean(sentiment(Utterance_text)$sentiment, na.rm = TRUE))
install.packages("IRkernel")
IRkernel::installspec(user = FALSE)  # system-wide install
IRkernel::installspec(user = FALSE)  # system-wide install
install.packages("IRkernel")
IRkernel::installspec(name = "ir44", displayname = "R 4.4.1")
shiny::runApp('D:/Monash/S2/5147/DVP/Yu-Jung_Ho_33531315_Code')
shiny::runApp('D:/Monash/S2/5147/DVP/Yu-Jung_Ho_33531315_Code')
sensor_df <- read_csv("on-street-parking-bay-sensors.csv")
library(dplyr)
sensor_df <- read_csv("on-street-parking-bay-sensors.csv")
installed.packages("readr")
library(tidyverse)
library(shiny)
library(leaflet)
library(tidyverse)
library(dplyr)
sensor_df <- read_csv("on-street-parking-bay-sensors.csv")
sensor_df
setwd("C:/Users/malon/Desktop/5120/Onboarding/notebooks/Onboarding_US2.1")
sensor_df <- read_csv("on-street-parking-bay-sensors.csv")
sensor_df
sensor_df <- read_csv("on-street-parking-bay-sensors.csv")
sensor_df <- sensor_df %>% separate(Location, into = c("Latitude", "Longitude", sep = ",", convert = T))
head(sensor_df)
sensor_df <- read_csv("on-street-parking-bay-sensors.csv")
sensor_df <- sensor_df %>% separate(Location, into = c("Latitude", "Longitude", sep = ","))
head(sensor_df)
sensor_df <- read_csv("on-street-parking-bay-sensors.csv")
sensor_df <- sensor_df %>% separate(Location, into = c("Latitude", "Longitude"), sep = ",")
head(sensor_df)
library(geosphere)
avaiable_parking <- sensor_df %>% filter(Status_Description == "Unoccupied") %>%
mutate(Latitude = as.numeric(str_trim(Latitude)), Longitude = as.numeric(str_trim(Longitude)))
avaiable_parking
avaiable_parking$Latitude
avaiable_parking
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
install.packages(c("httr", "jsonlite", "dplyr"))
install.packages(c("httr", "jsonlite", "dplyr"))
install.packages(c("httr", "jsonlite", "dplyr"))
shiny::runApp()
get_avaiable_spots <- function(limit = 100){
url <- "https://data.melbourne.vic.gov.au/api/explore/v2.1/catalog/datasets/on-street-parking-bay-sensors/records?where=status_description%20%3D%20%22Unoccupied%22&limit=100"
res <- GET(url)
content_json <- content(res, as = "text", encoding = "UTF-8")
data <- fromJSON(content_json, flatten = TRUE)$results
# Extract latitude and longitude
data <- data %>%
mutate(
Latitude = as.numeric(geo_point_2d.lat),
Longitude = as.numeric(geo_point_2d.lon)
) %>%
select(status_description, zone_number, kerbsideid, Latitude, Longitude)
return(data)
}
avaiable_parking <- get_avaiable_spots()
library(httr)
library(jsonlite)
library(dplyr)
library(geosphere)
return(data)
get_avaiable_spots <- function(limit = 100){
url <- "https://data.melbourne.vic.gov.au/api/explore/v2.1/catalog/datasets/on-street-parking-bay-sensors/records?where=status_description%20%3D%20%22Unoccupied%22&limit=100"
res <- GET(url)
content_json <- content(res, as = "text", encoding = "UTF-8")
data <- fromJSON(content_json, flatten = TRUE)$results
# Extract latitude and longitude
data <- data %>%
mutate(
Latitude = as.numeric(geo_point_2d.lat),
Longitude = as.numeric(geo_point_2d.lon)
) %>%
select(status_description, zone_number, kerbsideid, Latitude, Longitude)
return(data)
}
return(data)
get_avaiable_spots <- function(limit = 100){
url <- "https://data.melbourne.vic.gov.au/api/explore/v2.1/catalog/datasets/on-street-parking-bay-sensors/records?where=status_description%20%3D%20%22Unoccupied%22&limit=100"
res <- GET(url)
content_json <- content(res, as = "text", encoding = "UTF-8")
data <- fromJSON(content_json, flatten = TRUE)$results
# Extract latitude and longitude
data <- data %>%
mutate(
Latitude = as.numeric(geo_point_2d.lat),
Longitude = as.numeric(geo_point_2d.lon)
) %>%
select(status_description, zone_number, kerbsideid, Latitude, Longitude)
return(data)
}
avaiable_parking <- get_avaiable_spots()
return(data)
get_avaiable_spots <- function(limit = 100){
url <- "https://data.melbourne.vic.gov.au/api/explore/v2.1/catalog/datasets/on-street-parking-bay-sensors/records?where=status_description%20%3D%20%22Unoccupied%22&limit=100"
res <- GET(url)
content_json <- content(res, as = "text", encoding = "UTF-8")
data <- fromJSON(content_json, flatten = TRUE)$results
# Extract latitude and longitude
data <- data %>%
mutate(
Latitude = as.numeric(location.lat),
Longitude = as.numeric(location.lon)
) %>%
select(status_description, zone_number, kerbsideid, Latitude, Longitude)
return(data)
}
avaiable_parking <- get_avaiable_spots()
runApp()
runApp()
runApp()
head(avaiable_parking)
View(avaiable_parking)
runApp()
runApp()
runApp()
View(avaiable_parking)
runApp()
shiny::runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
library(shiny)
library(leaflet)
library(tidyverse)
library(httr)
library(jsonlite)
library(dplyr)
library(geosphere)
setwd("C:/Users/malon/Desktop/5120/Onboarding/notebooks/Onboarding_US2.3")
hist_df <- read_csv("on-street-parking-bay-historical.csv")
head(hist_df)
hist_df <- read_csv("on-street-parking-bay-historical.csv")
install.packages("readxl")
library(readxl)
hist_df <- read_xlsx("on-street-parking-bay-historical.xlsx")
head(hist_df)
setwd("C:/Users/malon/Desktop/5120/Onboarding/notebooks/Onboarding_US2.3")
hist_df <- read_xlsx("on-street-parking-bay-historical.xlsx")
hist_df <- read_xlsx("on-street-parking-bays-historical.xlsx")
head(hist_df)
prob_df <- hist_df %>%
group_by(KerbsideID, Zone_Number, Location, Status_Description) %>%
summarise(Count = n(), .groups = 'drop') %>%
group_by(KerbsideID) %>%
mutate(Total = sum(Count),
Prob_Unoccupied = ifelse(Status_Description == "Unoccupied", Count / Total, NA)) %>%
filter(Status_Description == "Unoccupied") %>%
select(Zone_Number, KerbsideID, Location, Status_Description, Prob_Unoccupied)
prob_df
distinct(prob_df$KerbsideID)
View(prob_df)
length(unique(prob_df$KerbsideID))
length(unique(hist_df$KerbsideID))
hist_df %>%
group_by(KerbsideID, Zone_Number, Location, Status_Description) %>%
summarise(Count = n(), .groups = 'drop')
prob <- hist_df %>%
group_by(KerbsideID, Zone_Number, Location, Status_Description) %>%
summarise(Count = n(), .groups = 'drop') %>%
pivot_wider(names_from = Status_Description, values_from = Count, values_fill = 0) %>%
mutate(
Total = rowSums(across(c(Present, Unoccupied), ~ .x, .names = "raw_{col}")),
Prob_Unoccupied = ifelse(Total > 0, Unoccupied / Total, NA),
Status_Description = "Unoccupied"  # just to match the original structure
) %>%
select(Zone_Number, KerbsideID, Location, Status_Description, Prob_Unoccupied)
prob_df <- hist_df %>%
group_by(KerbsideID, Zone_Number, Location, Status_Description) %>%
summarise(Count = n(), .groups = 'drop') %>%
pivot_wider(names_from = Status_Description, values_from = Count, values_fill = 0) %>%
mutate(
Total = rowSums(across(c(Present, Unoccupied), ~ .x, .names = "raw_{col}")),
Prob_Unoccupied = ifelse(Total > 0, Unoccupied / Total, NA),
Status_Description = "Unoccupied"  # just to match the original structure
) %>%
select(Zone_Number, KerbsideID, Location, Status_Description, Prob_Unoccupied)
prob_df
prob_df <- prob_df %>% separate(Location, into = c("Latitude", "Longitude"), sep = ",") %>%
mutate(Latitude = as.numeric(str_trim(Latitude)), Longitude = as.numeric(str_trim(Longitude)))
prob_df
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
hist_df <- read_xlsx("on-street-parking-bays-historical.xlsx")
hist_df <- read_xlsx("on-street-parking-bays-historical.xlsx")
runApp()
runApp()
runApp()
runApp()
runApp()
